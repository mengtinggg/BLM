{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "input_file_name = 'Twitter5July_Data.txt'\n",
    "retweet_file_name = 'TwitterRetweet.gml'\n",
    "hashtag_file_name = \"TwitterHashtags.gml\"\n",
    "MINIMUM_EDGE_WEIGHT = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### File Loading ###\n",
    "\n",
    "tweets_texts = []\n",
    "tweets_users = []\n",
    "tweets_file = open(input_file_name, \"r\")\n",
    "for line in tweets_file:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_texts.append(tweet['text'].encode('utf-8'))\n",
    "        tweets_users.append(tweet['user']['screen_name'])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "gml written\n"
    }
   ],
   "source": [
    "### Writing Retweets to gml ###\n",
    "output_file = open(retweet_file_name, \"w\")\n",
    "output_file.write(\"graph\\n\")\n",
    "output_file.write(\"[\\n\")\n",
    "\n",
    "counter = 0\n",
    "max_length = len(tweets_texts)\n",
    "pairwise_counter_dictionary = defaultdict(int)\n",
    "user_id = 0\n",
    "users = {}\n",
    "while counter < max_length:\n",
    "    text = tweets_texts[counter]\n",
    "    text = text.strip()\n",
    "    text_tokens = text.split()\n",
    "\n",
    "    from_user = tweets_users[counter]\n",
    "    prev_token = \"\"\n",
    "    for token in text_tokens:\n",
    "        token = token.decode('utf-8')\n",
    "        \n",
    "        if prev_token == 'RT' and token.startswith('@'):\n",
    "            #print (token)\n",
    "            token = token.replace(\":\", \"\")\n",
    "            to_user = token.replace(\"@\", \"\")\n",
    "            #print (from_user + ',' + to_user)\n",
    "\n",
    "            from_user_id = \"\"\n",
    "            to_user_id = \"\"\n",
    "            if (from_user in users) == False:\n",
    "                users[from_user] = user_id\n",
    "                user_id = user_id + 1\n",
    "            from_user_id = users[from_user]\n",
    "            if (to_user in users) == False:\n",
    "                users[to_user] = user_id\n",
    "                user_id = user_id + 1\n",
    "            to_user_id = users[to_user]\n",
    "\n",
    "            # increment counter\n",
    "            pairwise_counter_dictionary[from_user_id, to_user_id] += 1\n",
    "\n",
    "        prev_token = token\n",
    "\n",
    "    # while loop counter\n",
    "    counter = counter + 1\n",
    "\n",
    "# print all nodes\n",
    "for key in users.keys():\n",
    "    output_file.write(\"  node\\n\")\n",
    "    output_file.write(\"  [\\n\")\n",
    "    output_file.write(\"    id \" + str(users[key]) + \"\\n\")\n",
    "    output_file.write(\"    label \\\"\" + key + \"\\\"\" + \"\\n\")\n",
    "    output_file.write(\"  ]\\n\")\n",
    "\n",
    "# print all edges\n",
    "for keys in pairwise_counter_dictionary.keys():\n",
    "    output_file.write(\"  edge\\n\")\n",
    "    output_file.write(\"  [\\n\")\n",
    "    output_file.write(\"    source \" + str(keys[0]) + \"\\n\")\n",
    "    output_file.write(\"    target \" + str(keys[1]) + \"\\n\")\n",
    "    output_file.write(\"    value \" + str(pairwise_counter_dictionary[keys[0], keys[1]]) + \"\\n\")\n",
    "    output_file.write(\"  ]\\n\")\n",
    "\n",
    "output_file.write(\"]\\n\")\n",
    "output_file.close()\n",
    "print(\"gml written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "gml written\n"
    }
   ],
   "source": [
    "### Writing Hashtags to gml ###\n",
    "output_file = open(hashtag_file_name, \"w\", encoding= \"utf-8\")\n",
    "output_file.write(\"graph\\n\")\n",
    "output_file.write(\"[\\n\")\n",
    "counter = 0\n",
    "max_length = len(tweets_texts)\n",
    "pairwise_counter_dictionary = defaultdict(int)\n",
    "hashtags = {}\n",
    "hashtag_id = 0\n",
    "while counter < max_length:\n",
    "    text = tweets_texts[counter]\n",
    "    text = text.lower()\n",
    "    text = text.strip()    \n",
    "    text_tokens = text.split()\n",
    "    \n",
    "    hashtag_tokens = []\n",
    "    for token in text_tokens:\n",
    "        token = token.decode('utf-8')\n",
    "        \n",
    "        if token.startswith(\"#\"):\n",
    "            token = token.replace(\"#\", \"\")\n",
    "            hashtag_tokens.append(token)\n",
    "\n",
    "    #print hashtag_tokens\n",
    "    if len(hashtag_tokens) > 1:\n",
    "        for i in range(0, len(hashtag_tokens)):\n",
    "            for j in range((i + 1), len(hashtag_tokens)):\n",
    "                #print ()\"i: \" + str(i) + \", j: \" + str(j))\n",
    "                left_id = \"\"\n",
    "                right_id = \"\"\n",
    "                if(hashtag_tokens[i] in hashtags.keys()) == False:\n",
    "                    hashtags[hashtag_tokens[i]] = hashtag_id\n",
    "                    hashtag_id = hashtag_id + 1\n",
    "                left_id = hashtags[hashtag_tokens[i]]\n",
    "                if(hashtag_tokens[j] in hashtags.keys()) == False:\n",
    "                    hashtags[hashtag_tokens[j]] = hashtag_id\n",
    "                    hashtag_id = hashtag_id + 1\n",
    "                right_id = hashtags[hashtag_tokens[j]]\n",
    "                #increment the counter\n",
    "                if pairwise_counter_dictionary[left_id, right_id] == None:\n",
    "                    if pairwise_counter_dictionary[right_id, left_id] == None:\n",
    "                        pairwise_counter_dictionary[left_id, right_id] = 1\n",
    "                    else:\n",
    "                        pairwise_counter_dictionary[right_id, left_id] = pairwise_counter_dictionary[right_id, left_id] + 1\n",
    "                else:\n",
    "                    pairwise_counter_dictionary[left_id, right_id] = pairwise_counter_dictionary[left_id, right_id] + 1\n",
    "    #print (pairwise_counter_dictionary)\n",
    "    #exit(1)\n",
    "    # while loop counter\n",
    "    counter = counter + 1\n",
    "\n",
    "# print all edges\n",
    "# print only those whose edge weight > 3\n",
    "keys_included = defaultdict(int)\n",
    "for keys in pairwise_counter_dictionary.keys():\n",
    "    if (pairwise_counter_dictionary[keys[0], keys[1]]) >= MINIMUM_EDGE_WEIGHT:\n",
    "        keys_included[keys[0]] += 1\n",
    "        keys_included[keys[1]] += 1\n",
    "\n",
    "# print all nodes\n",
    "for key in hashtags.keys():\n",
    "    if hashtags[key] in keys_included.keys():\n",
    "        output_file.write(\"  node\\n\")\n",
    "        output_file.write(\"  [\\n\")\n",
    "        output_file.write(\"    id \" + str(hashtags[key]) + \"\\n\")\n",
    "        output_file.write(\"    label \\\"\" + key + \"\\\"\" + \"\\n\")\n",
    "        output_file.write(\"  ]\\n\")\n",
    "\n",
    "# print all edges\n",
    "# print only those whose edge weight > 3\n",
    "for keys in pairwise_counter_dictionary.keys():\n",
    "    if (pairwise_counter_dictionary[keys[0], keys[1]]) >= MINIMUM_EDGE_WEIGHT:\n",
    "        output_file.write(\"  edge\\n\")\n",
    "        output_file.write(\"  [\\n\")\n",
    "        output_file.write(\"    source \" + str(keys[0]) + \"\\n\")\n",
    "        output_file.write(\"    target \" + str(keys[1]) + \"\\n\")\n",
    "        output_file.write(\"    value \" + str(pairwise_counter_dictionary[keys[0], keys[1]]) + \"\\n\")\n",
    "        output_file.write(\"  ]\\n\")\n",
    "\n",
    "output_file.write(\"]\\n\")\n",
    "output_file.close()\n",
    "\n",
    "print(\"gml written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitprogramdatavirtualenvfdc9b17c209e4355b8cd06321c70cf29",
   "display_name": "Python 3.7.3 64-bit ('ProgramData': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}